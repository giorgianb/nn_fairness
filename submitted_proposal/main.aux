\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{liu2019algorithms}
\citation{tran2020verification}
\citation{katz2017reluplex}
\citation{gehr2018ai2}
\citation{ivanov2019verisig}
\citation{xiang2020reachable}
\citation{tran2019safety}
\citation{tran2020verification}
\citation{xingjian2015convolutional}
\citation{vnncomp2021}
\citation{jia2019certified}
\citation{ko2019popqorn}
\citation{shi2020robustness}
\citation{du2021cert}
\citation{ryou2021scalable}
\citation{bonaert2021fast}
\citation{duggirala2016parsimonious}
\citation{bak2017hscc}
\citation{bak2019hscc}
\citation{tran2019star}
\citation{bak2020cav}
\citation{bak2021nnenum}
\citation{bak2021nnenum}
\citation{urban2020perfectly}
\citation{galhotra2017fairness}
\citation{ruoss2020learning}
\citation{duggirala2016parsimonious}
\citation{tran2020cav}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The star set approach can provide tight bounds on nonlinear layers such as softmax. The blue set is the real possible outputs of a neuron, projected onto the input ($x$ axis) and output ($y$ axis) of a single neuron.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:softmax}{{1}{2}{The star set approach can provide tight bounds on nonlinear layers such as softmax. The blue set is the real possible outputs of a neuron, projected onto the input ($x$ axis) and output ($y$ axis) of a single neuron}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Each partition $\Theta $ of the network input space is used as the domain for integration over a given input probability density function $P$, calculating a probability of the input space with a fixed output classification. Repeating and summing over all partitions, we can evaluate fairness metrics for the network.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:input_split}{{2}{3}{Each partition $\Theta $ of the network input space is used as the domain for integration over a given input probability density function $P$, calculating a probability of the input space with a fixed output classification. Repeating and summing over all partitions, we can evaluate fairness metrics for the network}{figure.2}{}}
\citation{vnncomp2021}
\bibstyle{abbrv}
\bibdata{refs}
\bibcite{bak2021nnenum}{1}
\bibcite{bak2017hscc}{2}
\bibcite{vnncomp2021}{3}
\bibcite{bak2020cav}{4}
\bibcite{bak2019hscc}{5}
\bibcite{bonaert2021fast}{6}
\bibcite{du2021cert}{7}
\bibcite{duggirala2016parsimonious}{8}
\bibcite{galhotra2017fairness}{9}
\bibcite{gehr2018ai2}{10}
\bibcite{ivanov2019verisig}{11}
\bibcite{jia2019certified}{12}
\bibcite{katz2017reluplex}{13}
\bibcite{ko2019popqorn}{14}
\bibcite{liu2019algorithms}{15}
\bibcite{ruoss2020learning}{16}
\bibcite{ryou2021scalable}{17}
\bibcite{shi2020robustness}{18}
\bibcite{tran2020cav}{19}
\bibcite{tran2019safety}{20}
\bibcite{tran2019star}{21}
\bibcite{tran2020verification}{22}
\bibcite{urban2020perfectly}{23}
\bibcite{xiang2020reachable}{24}
\bibcite{xingjian2015convolutional}{25}
\newlabel{TotPages}{{9}{9}{}{page.9}{}}
